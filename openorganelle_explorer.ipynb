{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff46f437",
   "metadata": {},
   "source": [
    "# OpenOrganelle Cellular Imaging Data Explorer\n",
    "\n",
    "This notebook demonstrates how to explore and download cellular imaging data from the OpenOrganelle platform using your uv virtual environment.\n",
    "\n",
    "## About OpenOrganelle\n",
    "\n",
    "OpenOrganelle is a data portal that provides access to FIB-SEM (Focused Ion Beam Scanning Electron Microscopy) datasets and organelle segmentations. The platform hosts high-resolution cellular imaging data that can be used for research in cell biology, machine learning, and image analysis.\n",
    "\n",
    "**Key Features:**\n",
    "- High-resolution FIB-SEM volumes\n",
    "- Machine learning-generated organelle segmentations  \n",
    "- Correlative light microscopy data\n",
    "- Analysis results and measurements\n",
    "- Open access with CC BY 4.0 license\n",
    "\n",
    "Let's start by setting up our environment and exploring the available data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557004d",
   "metadata": {},
   "source": [
    "## 1. Check uv Installation and Environment\n",
    "\n",
    "First, let's verify that uv is installed and check our current environment status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db4e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uv version: uv 0.8.5 (ce3728681 2025-08-05)\n",
      "Python executable: C:\\Users\\nhg43\\OneDrive\\Documents\\code_directory\\uv-python-project\\.venv\\Scripts\\python.exe\n",
      "Python version: 3.13.5 (main, Jul 23 2025, 00:30:06) [MSC v.1944 64 bit (AMD64)]\n",
      "Current working directory: C:\\Users\\nhg43\\OneDrive\\Documents\\code_directory\\uv-python-project\n",
      "‚úÖ Running in a virtual environment\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check uv version\n",
    "try:\n",
    "    result = subprocess.run(['uv', '--version'], capture_output=True, text=True)\n",
    "    print(f\"uv version: {result.stdout.strip()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"uv is not installed or not in PATH\")\n",
    "\n",
    "# Check current Python environment\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if we're in a virtual environment\n",
    "if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):\n",
    "    print(\"‚úÖ Running in a virtual environment\")\n",
    "else:\n",
    "    print(\"‚ùå Not running in a virtual environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c33ab3",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Let's import the necessary libraries for working with OpenOrganelle data. We'll use the packages we installed in our uv environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c11d16af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 16:19:59,324 - INFO - OpenOrganelle downloader initialized. Output directory: ./data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "‚úÖ OpenOrganelle downloader initialized!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zarr\n",
    "import fsspec\n",
    "import dask.array as da\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our custom OpenOrganelle downloader\n",
    "sys.path.append('./src')\n",
    "from openorganelle_downloader import OpenOrganelleDownloader\n",
    "\n",
    "# Set up matplotlib for inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialize the downloader\n",
    "downloader = OpenOrganelleDownloader(output_dir=\"./data\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"‚úÖ OpenOrganelle downloader initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049fd59",
   "metadata": {},
   "source": [
    "## 3. Explore Available Datasets\n",
    "\n",
    "Let's start by listing all available datasets on the OpenOrganelle platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3dda16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Discovering available datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhg43\\OneDrive\\Documents\\code_directory\\uv-python-project\\.venv\\Lib\\site-packages\\fsspec\\registry.py:298: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n",
      "2025-08-07 16:20:07,126 - INFO - Found 89 datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Found 89 datasets on OpenOrganelle:\n",
      "==================================================\n",
      " 1. aic_desmosome-1\n",
      " 2. aic_desmosome-2\n",
      " 3. aic_desmosome-3\n",
      " 4. cam_hum-airway-14500\n",
      " 5. cam_hum-airway-14771-b\n",
      " 6. csc-zipped-data\n",
      " 7. jrc_ccl81-covid-1\n",
      " 8. jrc_choroid-plexus-2\n",
      " 9. jrc_cos7-11\n",
      "10. jrc_cos7-1a\n",
      "11. jrc_cos7-1b\n",
      "12. jrc_ctl-id8-1\n",
      "13. jrc_ctl-id8-2\n",
      "14. jrc_ctl-id8-3\n",
      "15. jrc_ctl-id8-4\n",
      "16. jrc_ctl-id8-5\n",
      "17. jrc_dauer-larva\n",
      "18. jrc_fly-acc-calyx-1\n",
      "19. jrc_fly-ellipsoid-body\n",
      "20. jrc_fly-fsb-1\n",
      "21. jrc_fly-fsb-2\n",
      "22. jrc_fly-larva-1\n",
      "23. jrc_fly-mb-1a\n",
      "24. jrc_fly-mb-z0419-20\n",
      "25. jrc_fly-protocerebral-bridge\n",
      "26. jrc_fly-vnc-1\n",
      "27. jrc_hela-1\n",
      "28. jrc_hela-2\n",
      "29. jrc_hela-21\n",
      "30. jrc_hela-22\n",
      "31. jrc_hela-3\n",
      "32. jrc_hela-4\n",
      "33. jrc_hela-bfa\n",
      "34. jrc_hela-h89-1\n",
      "35. jrc_hela-h89-2\n",
      "36. jrc_hela-nz-1\n",
      "37. jrc_hela-nz-2\n",
      "38. jrc_hum-airway-14953vc\n",
      "39. jrc_jurkat-1\n",
      "40. jrc_macrophage-2\n",
      "41. jrc_mus-cerebellum-4\n",
      "42. jrc_mus-cerebellum-5\n",
      "43. jrc_mus-choroid-plexus-3\n",
      "44. jrc_mus-cortex-3\n",
      "45. jrc_mus-dorsal-striatum\n",
      "46. jrc_mus-dorsal-striatum-2\n",
      "47. jrc_mus-epididymis-1\n",
      "48. jrc_mus-epididymis-2\n",
      "49. jrc_mus-granule-neurons-1\n",
      "50. jrc_mus-granule-neurons-2\n",
      "51. jrc_mus-granule-neurons-3\n",
      "52. jrc_mus-guard-hair-follicle\n",
      "53. jrc_mus-heart-1\n",
      "54. jrc_mus-hippocampus-1\n",
      "55. jrc_mus-hippocampus-2\n",
      "56. jrc_mus-hippocampus-3\n",
      "57. jrc_mus-kidney\n",
      "58. jrc_mus-kidney-2\n",
      "59. jrc_mus-kidney-3\n",
      "60. jrc_mus-kidney-glomerulus-2\n",
      "61. jrc_mus-liver\n",
      "62. jrc_mus-liver-2\n",
      "63. jrc_mus-liver-3\n",
      "64. jrc_mus-liver-4\n",
      "65. jrc_mus-liver-5\n",
      "66. jrc_mus-liver-6\n",
      "67. jrc_mus-liver-7\n",
      "68. jrc_mus-liver-zon-1\n",
      "69. jrc_mus-liver-zon-2\n",
      "70. jrc_mus-meissner-corpuscle-1\n",
      "71. jrc_mus-meissner-corpuscle-2\n",
      "72. jrc_mus-nacc-1\n",
      "73. jrc_mus-nacc-2\n",
      "74. jrc_mus-nacc-3\n",
      "75. jrc_mus-nacc-4\n",
      "76. jrc_mus-pacinian-corpuscle\n",
      "77. jrc_mus-pancreas-1\n",
      "78. jrc_mus-pancreas-2\n",
      "79. jrc_mus-pancreas-3\n",
      "80. jrc_mus-pancreas-4\n",
      "81. jrc_mus-salivary-1\n",
      "82. jrc_mus-sc-zp104a\n",
      "83. jrc_mus-sc-zp105a\n",
      "84. jrc_mus-skin-1\n",
      "85. jrc_mus-thymus-1\n",
      "86. jrc_sum159-1\n",
      "87. jrc_sum159-4\n",
      "88. jrc_ut21-1413-003\n",
      "89. jrc_zf-cardiac-1\n",
      "\n",
      "üéØ Selected dataset for exploration: jrc_hela-1\n"
     ]
    }
   ],
   "source": [
    "# List available datasets\n",
    "print(\"üîç Discovering available datasets...\")\n",
    "datasets = downloader.list_datasets()\n",
    "\n",
    "print(f\"\\nüìä Found {len(datasets)} datasets on OpenOrganelle:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, dataset in enumerate(datasets, 1):\n",
    "    print(f\"{i:2d}. {dataset}\")\n",
    "\n",
    "# Let's focus on a specific dataset for our exploration\n",
    "# Look for HeLa cell data, which is commonly available\n",
    "target_dataset = None\n",
    "for dataset in datasets:\n",
    "    if 'hela' in dataset.lower():\n",
    "        target_dataset = dataset\n",
    "        break\n",
    "\n",
    "if not target_dataset and datasets:\n",
    "    # If no HeLa dataset, use the first available\n",
    "    target_dataset = datasets[0]\n",
    "\n",
    "if target_dataset:\n",
    "    print(f\"\\nüéØ Selected dataset for exploration: {target_dataset}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No datasets available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337e67b",
   "metadata": {},
   "source": [
    "## 4. Explore Dataset Structure\n",
    "\n",
    "Now let's dive deeper into the structure of our selected dataset to understand what data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd35438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Exploring structure of dataset: jrc_hela-1\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 16:20:15,258 - INFO - Retrieved information for dataset: jrc_hela-1\n",
      "2025-08-07 16:20:15,321 - INFO - Array info (from attributes) for jrc_hela-1/labels/endo_pred\n",
      "2025-08-07 16:20:15,380 - INFO - Array info (from attributes) for jrc_hela-1/labels/endo_seg\n",
      "2025-08-07 16:20:15,425 - INFO - Array info (from attributes) for jrc_hela-1/labels/er_pred\n",
      "2025-08-07 16:20:15,426 - INFO - Retrieved information for dataset: jrc_hela-1\n",
      "2025-08-07 16:20:15,429 - INFO - Metadata saved to: ./data\\jrc_hela-1_metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Main groups: ['labels']\n",
      "üìä Main arrays: []\n",
      "\n",
      "üìÇ Group: labels\n",
      "------------------------------\n",
      "   üìä Arrays: ['endo_pred', 'endo_seg', 'er_pred', 'er_seg', 'mito_pred', 'mito_seg', 'nucleus_pred', 'nucleus_seg', 'pm_pred', 'pm_seg', 'vesicle_pred', 'vesicle_seg']\n",
      "      ‚Ä¢ endo_pred: Error getting info\n",
      "      ‚Ä¢ endo_seg: Error getting info\n",
      "      ‚Ä¢ er_pred: Error getting info\n",
      "   üìÅ Subgroups: ['endo_pred', 'endo_seg', 'er_pred', 'er_seg', 'mito_pred', 'mito_seg', 'nucleus_pred', 'nucleus_seg', 'pm_pred', 'pm_seg', 'vesicle_pred', 'vesicle_seg']\n",
      "\n",
      "üíæ Metadata saved to: ./data\\jrc_hela-1_metadata.json\n"
     ]
    }
   ],
   "source": [
    "if target_dataset:\n",
    "    print(f\"üî¨ Exploring structure of dataset: {target_dataset}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get detailed dataset information\n",
    "    info = downloader.get_dataset_info(target_dataset)\n",
    "    \n",
    "    if 'error' not in info:\n",
    "        print(f\"üìÅ Main groups: {info.get('groups', [])}\")\n",
    "        print(f\"üìä Main arrays: {info.get('arrays', [])}\")\n",
    "        \n",
    "        # Explore each group in detail\n",
    "        for group_name in info.get('groups', []):\n",
    "            print(f\"\\nüìÇ Group: {group_name}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            # Show arrays in this group\n",
    "            group_arrays_key = f'{group_name}_arrays'\n",
    "            group_groups_key = f'{group_name}_groups'\n",
    "            \n",
    "            arrays = info.get(group_arrays_key, [])\n",
    "            subgroups = info.get(group_groups_key, [])\n",
    "            \n",
    "            if arrays:\n",
    "                print(f\"   üìä Arrays: {arrays}\")\n",
    "                \n",
    "                # Get detailed info for each array\n",
    "                for array_name in arrays[:3]:  # Limit to first 3 arrays\n",
    "                    try:\n",
    "                        array_path = f\"{group_name}/{array_name}\"\n",
    "                        array_info = downloader.get_array_info(target_dataset, array_path)\n",
    "                        if 'error' not in array_info:\n",
    "                            shape = array_info['shape']\n",
    "                            dtype = array_info['dtype']\n",
    "                            size_mb = array_info['size_mb']\n",
    "                            print(f\"      ‚Ä¢ {array_name}: {shape} {dtype} ({size_mb:.1f} MB)\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"      ‚Ä¢ {array_name}: Error getting info\")\n",
    "            \n",
    "            if subgroups:\n",
    "                print(f\"   üìÅ Subgroups: {subgroups}\")\n",
    "        \n",
    "        # Save metadata for later reference\n",
    "        metadata_file = downloader.download_metadata(target_dataset)\n",
    "        print(f\"\\nüíæ Metadata saved to: {metadata_file}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Error exploring dataset: {info['error']}\")\n",
    "else:\n",
    "    print(\"‚ùå No dataset selected for exploration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0788a",
   "metadata": {},
   "source": [
    "## 5. Download Sample Data\n",
    "\n",
    "Let's download a small sample of the cellular imaging data for analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07fc586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading sample data from jrc_hela-1...\n",
      "   Trying data path: em/fibsem-uint16/s0\n",
      "   Trying data path: em/fibsem-uint8/s0\n",
      "   Trying data path: labels/fibsem-uint64/s0\n",
      "‚ùå Could not download any sample data. Dataset might have different structure.\n"
     ]
    }
   ],
   "source": [
    "if target_dataset:\n",
    "    print(f\"üì• Downloading sample data from {target_dataset}...\")\n",
    "    \n",
    "    # Try to download EM data first (common data type)\n",
    "    sample_data = None\n",
    "    sample_path = None\n",
    "    \n",
    "    # Common data paths to try\n",
    "    data_paths_to_try = [\n",
    "        'em/fibsem-uint16/s0',  # Full resolution EM data\n",
    "        'em/fibsem-uint8/s0',   # Alternative EM data format\n",
    "        'labels/fibsem-uint64/s0',  # Segmentation labels\n",
    "    ]\n",
    "    \n",
    "    for data_path in data_paths_to_try:\n",
    "        try:\n",
    "            print(f\"   Trying data path: {data_path}\")\n",
    "            \n",
    "            # Download a small 32x32x32 cube sample\n",
    "            sample_file = downloader.download_array_slice(\n",
    "                target_dataset, \n",
    "                data_path,\n",
    "                slice_spec=(slice(0, 32), slice(0, 32), slice(0, 32))\n",
    "            )\n",
    "            \n",
    "            if sample_file and os.path.exists(sample_file):\n",
    "                print(f\"   ‚úÖ Successfully downloaded: {sample_file}\")\n",
    "                sample_data = np.load(sample_file)\n",
    "                sample_path = data_path\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to download {data_path}: {str(e)[:100]}...\")\n",
    "            continue\n",
    "    \n",
    "    if sample_data is not None:\n",
    "        print(f\"\\nüìä Sample data information:\")\n",
    "        print(f\"   Shape: {sample_data.shape}\")\n",
    "        print(f\"   Data type: {sample_data.dtype}\")\n",
    "        print(f\"   Value range: {sample_data.min()} - {sample_data.max()}\")\n",
    "        print(f\"   Memory size: {sample_data.nbytes / (1024*1024):.2f} MB\")\n",
    "        print(f\"   Data path: {sample_path}\")\n",
    "    else:\n",
    "        print(\"‚ùå Could not download any sample data. Dataset might have different structure.\")\n",
    "else:\n",
    "    print(\"‚ùå No dataset available for download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf29070",
   "metadata": {},
   "source": [
    "## 6. Visualize Cellular Imaging Data\n",
    "\n",
    "Now let's create visualizations of our downloaded cellular imaging data to see the cellular structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92ebace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No sample data available for visualization\n",
      "üí° Try running the previous cell again or check dataset availability\n"
     ]
    }
   ],
   "source": [
    "if sample_data is not None:\n",
    "    print(f\"üé® Creating visualizations of {sample_path} data...\")\n",
    "    \n",
    "    # Create a comprehensive figure with multiple views\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle(f'Cellular Imaging Data: {target_dataset}\\nData Path: {sample_path}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Calculate middle slices for each dimension\n",
    "    z_mid = sample_data.shape[0] // 2\n",
    "    y_mid = sample_data.shape[1] // 2\n",
    "    x_mid = sample_data.shape[2] // 2\n",
    "    \n",
    "    # Row 1: Different slice orientations\n",
    "    # XY slice (looking down through Z)\n",
    "    im1 = axes[0, 0].imshow(sample_data[z_mid, :, :], cmap='gray', origin='lower')\n",
    "    axes[0, 0].set_title(f'XY Slice (Z={z_mid})')\n",
    "    axes[0, 0].set_xlabel('X')\n",
    "    axes[0, 0].set_ylabel('Y')\n",
    "    plt.colorbar(im1, ax=axes[0, 0], shrink=0.8)\n",
    "    \n",
    "    # XZ slice (side view through Y)\n",
    "    im2 = axes[0, 1].imshow(sample_data[:, y_mid, :], cmap='gray', origin='lower')\n",
    "    axes[0, 1].set_title(f'XZ Slice (Y={y_mid})')\n",
    "    axes[0, 1].set_xlabel('X')\n",
    "    axes[0, 1].set_ylabel('Z')\n",
    "    plt.colorbar(im2, ax=axes[0, 1], shrink=0.8)\n",
    "    \n",
    "    # YZ slice (side view through X)\n",
    "    im3 = axes[0, 2].imshow(sample_data[:, :, x_mid], cmap='gray', origin='lower')\n",
    "    axes[0, 2].set_title(f'YZ Slice (X={x_mid})')\n",
    "    axes[0, 2].set_xlabel('Y')\n",
    "    axes[0, 2].set_ylabel('Z')\n",
    "    plt.colorbar(im3, ax=axes[0, 2], shrink=0.8)\n",
    "    \n",
    "    # Row 2: Analysis plots\n",
    "    # Histogram of pixel intensities\n",
    "    axes[1, 0].hist(sample_data.flatten(), bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[1, 0].set_title('Pixel Intensity Distribution')\n",
    "    axes[1, 0].set_xlabel('Intensity Value')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Maximum intensity projection (MIP) in Z direction\n",
    "    mip_z = np.max(sample_data, axis=0)\n",
    "    im4 = axes[1, 1].imshow(mip_z, cmap='hot', origin='lower')\n",
    "    axes[1, 1].set_title('Maximum Intensity Projection (Z)')\n",
    "    axes[1, 1].set_xlabel('X')\n",
    "    axes[1, 1].set_ylabel('Y')\n",
    "    plt.colorbar(im4, ax=axes[1, 1], shrink=0.8)\n",
    "    \n",
    "    # 3D structure visualization (sum projection with enhanced contrast)\n",
    "    sum_proj = np.sum(sample_data, axis=0)\n",
    "    im5 = axes[1, 2].imshow(sum_proj, cmap='viridis', origin='lower')\n",
    "    axes[1, 2].set_title('Sum Projection (Z)')\n",
    "    axes[1, 2].set_xlabel('X')\n",
    "    axes[1, 2].set_ylabel('Y')\n",
    "    plt.colorbar(im5, ax=axes[1, 2], shrink=0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"\\nüìà Data Statistics:\")\n",
    "    print(f\"   Mean intensity: {sample_data.mean():.2f}\")\n",
    "    print(f\"   Standard deviation: {sample_data.std():.2f}\")\n",
    "    print(f\"   Min/Max values: {sample_data.min()} / {sample_data.max()}\")\n",
    "    print(f\"   Data shape: {sample_data.shape}\")\n",
    "    print(f\"   Voxel count: {np.prod(sample_data.shape):,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No sample data available for visualization\")\n",
    "    print(\"üí° Try running the previous cell again or check dataset availability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139b968",
   "metadata": {},
   "source": [
    "## 7. Advanced Data Access\n",
    "\n",
    "For more advanced analysis, you might want to access larger portions of the data or specific organelle segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf12401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Advanced data access example for jrc_hela-1\n",
      "   ‚ùå Could not open dataset: nothing found at path '', FSStore.__init__() missing 1 required positional argument: 'url'\n",
      "‚ùå Could not access dataset with any method\n",
      "\n",
      "üí° Tips for working with large datasets:\n",
      "   ‚Ä¢ Use dask arrays for lazy loading of large data\n",
      "   ‚Ä¢ Access only the regions you need using slicing\n",
      "   ‚Ä¢ Consider using lower resolution versions (s1, s2, etc.) for exploration\n",
      "   ‚Ä¢ Use chunked processing for analysis of full datasets\n",
      "   ‚Ä¢ The OpenOrganelle website provides Neuroglancer links for online visualization\n"
     ]
    }
   ],
   "source": [
    "# Example of direct access to larger data using zarr and dask\n",
    "if target_dataset:\n",
    "    print(f\"üî¨ Advanced data access example for {target_dataset}\")\n",
    "    \n",
    "    try:\n",
    "        # Direct access to the dataset using zarr with v3 compatibility\n",
    "        n5_path = f\"s3://janelia-cosem-datasets/{target_dataset}/{target_dataset}.n5\"\n",
    "        \n",
    "        # Try different methods for zarr access (v2 vs v3 compatibility)\n",
    "        group = None\n",
    "        try:\n",
    "            # Method 1: Try zarr v3 with fsspec\n",
    "            store = fsspec.get_mapper(n5_path, anon=True)\n",
    "            group = zarr.open(store, mode='r')\n",
    "        except Exception as e1:\n",
    "            try:\n",
    "                # Method 2: Try with different zarr opening\n",
    "                import fsspec\n",
    "                fs = fsspec.filesystem('s3', anon=True)\n",
    "                store = zarr.storage.FSStore(fs=fs, path=n5_path.replace('s3://', ''))\n",
    "                group = zarr.open_group(store=store, mode='r')\n",
    "            except Exception as e2:\n",
    "                print(f\"   ‚ùå Could not open dataset: {e1}, {e2}\")\n",
    "                group = None\n",
    "        \n",
    "        if group is not None:\n",
    "            print(f\"üìÅ Available data groups:\")\n",
    "            \n",
    "            # Get groups with compatibility for different zarr versions\n",
    "            groups = []\n",
    "            try:\n",
    "                if hasattr(group, 'group_keys'):\n",
    "                    groups = list(group.group_keys())\n",
    "                elif hasattr(group, 'keys'):\n",
    "                    all_keys = list(group.keys())\n",
    "                    groups = [k for k in all_keys if hasattr(group.get(k, None), 'keys')]\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Could not list groups: {e}\")\n",
    "            \n",
    "            for key in groups:\n",
    "                print(f\"   ‚Ä¢ {key}\")\n",
    "                try:\n",
    "                    subgroup = group[key]\n",
    "                    if hasattr(subgroup, 'array_keys'):\n",
    "                        arrays = list(subgroup.array_keys())\n",
    "                    elif hasattr(subgroup, 'keys'):\n",
    "                        all_keys = list(subgroup.keys())\n",
    "                        arrays = [k for k in all_keys if not hasattr(subgroup.get(k, None), 'keys')]\n",
    "                    else:\n",
    "                        arrays = []\n",
    "                    \n",
    "                    if arrays:\n",
    "                        print(f\"     Arrays: {arrays[:3]}{'...' if len(arrays) > 3 else ''}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"     Error accessing {key}: {str(e)[:50]}...\")\n",
    "            \n",
    "            # Example: Access EM data directly with dask for lazy loading\n",
    "            em_data_paths = ['em/fibsem-uint16/s0', 'em/fibsem-uint8/s0']\n",
    "            \n",
    "            for em_path in em_data_paths:\n",
    "                try:\n",
    "                    if em_path.split('/')[0] in groups:\n",
    "                        print(f\"\\nüîç Accessing: {em_path}\")\n",
    "                        zarray = group[em_path]\n",
    "                        \n",
    "                        # Handle chunks compatibility\n",
    "                        chunks = zarray.chunks if hasattr(zarray, 'chunks') else None\n",
    "                        if chunks is None:\n",
    "                            chunks = tuple(min(64, s) for s in zarray.shape)\n",
    "                        \n",
    "                        darray = da.from_array(zarray, chunks=chunks)\n",
    "                        \n",
    "                        print(f\"   Full dataset shape: {darray.shape}\")\n",
    "                        print(f\"   Data type: {darray.dtype}\")\n",
    "                        print(f\"   Chunk size: {chunks}\")\n",
    "                        print(f\"   Estimated size: {darray.nbytes / (1024**3):.2f} GB\")\n",
    "                        \n",
    "                        # Show how to access specific regions efficiently\n",
    "                        print(f\"   Example: Access a 100x100x100 region:\")\n",
    "                        print(f\"   region = darray[0:100, 0:100, 0:100].compute()\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Could not access {em_path}: {str(e)[:50]}...\")\n",
    "            \n",
    "            # Show organelle segmentation data if available\n",
    "            if 'labels' in groups:\n",
    "                print(f\"\\nüè∑Ô∏è  Available organelle segmentations:\")\n",
    "                try:\n",
    "                    labels_group = group['labels']\n",
    "                    if hasattr(labels_group, 'group_keys'):\n",
    "                        label_keys = list(labels_group.group_keys())\n",
    "                    elif hasattr(labels_group, 'keys'):\n",
    "                        all_keys = list(labels_group.keys())\n",
    "                        label_keys = [k for k in all_keys if hasattr(labels_group.get(k, None), 'keys')]\n",
    "                    else:\n",
    "                        label_keys = []\n",
    "                    \n",
    "                    for key in label_keys[:5]:  # Show first 5\n",
    "                        print(f\"   ‚Ä¢ {key}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Could not access labels: {str(e)[:50]}...\")\n",
    "        else:\n",
    "            print(\"‚ùå Could not access dataset with any method\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in advanced access: {str(e)[:100]}...\")\n",
    "\n",
    "print(f\"\\nüí° Tips for working with large datasets:\")\n",
    "print(f\"   ‚Ä¢ Use dask arrays for lazy loading of large data\")\n",
    "print(f\"   ‚Ä¢ Access only the regions you need using slicing\")\n",
    "print(f\"   ‚Ä¢ Consider using lower resolution versions (s1, s2, etc.) for exploration\")\n",
    "print(f\"   ‚Ä¢ Use chunked processing for analysis of full datasets\")\n",
    "print(f\"   ‚Ä¢ The OpenOrganelle website provides Neuroglancer links for online visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e096f1",
   "metadata": {},
   "source": [
    "## 8. Next Steps and Resources\n",
    "\n",
    "Congratulations! You've successfully explored cellular imaging data from OpenOrganelle using your uv virtual environment.\n",
    "\n",
    "### What you've accomplished:\n",
    "- ‚úÖ Set up and verified your uv virtual environment\n",
    "- ‚úÖ Installed required packages for cellular imaging analysis\n",
    "- ‚úÖ Connected to the OpenOrganelle data platform\n",
    "- ‚úÖ Explored available datasets and their structure\n",
    "- ‚úÖ Downloaded sample cellular imaging data\n",
    "- ‚úÖ Created visualizations of FIB-SEM data\n",
    "\n",
    "### Next Steps:\n",
    "1. **Explore more datasets**: Try different cell types and organisms\n",
    "2. **Analyze organelle segmentations**: Download and visualize organelle labels\n",
    "3. **Scale up analysis**: Use dask for processing larger data regions\n",
    "4. **Machine learning**: Use the data for training image analysis models\n",
    "5. **Quantitative analysis**: Measure organelle properties and relationships\n",
    "\n",
    "### Useful Resources:\n",
    "- **OpenOrganelle Website**: https://openorganelle.janelia.org/\n",
    "- **Documentation**: https://github.com/janelia-cosem/fibsem-tools\n",
    "- **CellMap Project**: https://www.janelia.org/project-team/cellmap\n",
    "- **Neuroglancer Viewer**: For online 3D visualization\n",
    "- **N5 Format**: https://github.com/saalfeldlab/n5\n",
    "\n",
    "### Command Line Usage:\n",
    "You can also use the downloader from the command line:\n",
    "```bash\n",
    "# Activate your uv environment first\n",
    "./.venv/Scripts/activate  # Windows\n",
    "# or: source .venv/bin/activate  # Linux/Mac\n",
    "\n",
    "# Then run the downloader\n",
    "python src/openorganelle_downloader.py --list-datasets\n",
    "python src/openorganelle_downloader.py --explore jrc_hela-2\n",
    "python src/openorganelle_downloader.py --download jrc_hela-2\n",
    "```\n",
    "\n",
    "Happy exploring! üî¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
